{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from src.utils_clustering_v2 import load_labels_from_file, map_clusters_to_ground_truth, evaluate_clustering, generate_confusion_matrix\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data_preprocessing import preprocess_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T21:18:48.081087400Z",
     "start_time": "2024-02-16T21:18:48.067931300Z"
    }
   },
   "id": "2d9ae052d957949f",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] g2-1024-10\n",
      "[2/100] g2-1024-100\n",
      "[3/100] g2-1024-20\n",
      "[4/100] g2-1024-30\n",
      "[5/100] g2-1024-40\n",
      "[6/100] g2-1024-50\n",
      "[7/100] g2-1024-60\n",
      "[8/100] g2-1024-70\n",
      "[9/100] g2-1024-80\n",
      "[10/100] g2-1024-90\n",
      "[11/100] g2-128-10\n",
      "[12/100] g2-128-100\n",
      "[13/100] g2-128-20\n",
      "[14/100] g2-128-30\n",
      "[15/100] g2-128-40\n",
      "[16/100] g2-128-50\n",
      "[17/100] g2-128-60\n",
      "[18/100] g2-128-70\n",
      "[19/100] g2-128-80\n",
      "[20/100] g2-128-90\n",
      "[21/100] g2-16-10\n",
      "[22/100] g2-16-100\n",
      "[23/100] g2-16-20\n",
      "[24/100] g2-16-30\n",
      "[25/100] g2-16-40\n",
      "[26/100] g2-16-50\n",
      "[27/100] g2-16-60\n",
      "[28/100] g2-16-70\n",
      "[29/100] g2-16-80\n",
      "[30/100] g2-16-90\n",
      "[31/100] g2-2-10\n",
      "[32/100] g2-2-100\n",
      "[33/100] g2-2-20\n",
      "[34/100] g2-2-30\n",
      "[35/100] g2-2-40\n",
      "[36/100] g2-2-50\n",
      "[37/100] g2-2-60\n",
      "[38/100] g2-2-70\n",
      "[39/100] g2-2-80\n",
      "[40/100] g2-2-90\n",
      "[41/100] g2-256-10\n",
      "[42/100] g2-256-100\n",
      "[43/100] g2-256-20\n",
      "[44/100] g2-256-30\n",
      "[45/100] g2-256-40\n",
      "[46/100] g2-256-50\n",
      "[47/100] g2-256-60\n",
      "[48/100] g2-256-70\n",
      "[49/100] g2-256-80\n",
      "[50/100] g2-256-90\n",
      "[51/100] g2-32-10\n",
      "[52/100] g2-32-100\n",
      "[53/100] g2-32-20\n",
      "[54/100] g2-32-30\n",
      "[55/100] g2-32-40\n",
      "[56/100] g2-32-50\n",
      "[57/100] g2-32-60\n",
      "[58/100] g2-32-70\n",
      "[59/100] g2-32-80\n",
      "[60/100] g2-32-90\n",
      "[61/100] g2-4-10\n",
      "[62/100] g2-4-100\n",
      "[63/100] g2-4-20\n",
      "[64/100] g2-4-30\n",
      "[65/100] g2-4-40\n",
      "[66/100] g2-4-50\n",
      "[67/100] g2-4-60\n",
      "[68/100] g2-4-70\n",
      "[69/100] g2-4-80\n",
      "[70/100] g2-4-90\n",
      "[71/100] g2-512-10\n",
      "[72/100] g2-512-100\n",
      "[73/100] g2-512-20\n",
      "[74/100] g2-512-30\n",
      "[75/100] g2-512-40\n",
      "[76/100] g2-512-50\n",
      "[77/100] g2-512-60\n",
      "[78/100] g2-512-70\n",
      "[79/100] g2-512-80\n",
      "[80/100] g2-512-90\n",
      "[81/100] g2-64-10\n",
      "[82/100] g2-64-100\n",
      "[83/100] g2-64-20\n",
      "[84/100] g2-64-30\n",
      "[85/100] g2-64-40\n",
      "[86/100] g2-64-50\n",
      "[87/100] g2-64-60\n",
      "[88/100] g2-64-70\n",
      "[89/100] g2-64-80\n",
      "[90/100] g2-64-90\n",
      "[91/100] g2-8-10\n",
      "[92/100] g2-8-100\n",
      "[93/100] g2-8-20\n",
      "[94/100] g2-8-30\n",
      "[95/100] g2-8-40\n",
      "[96/100] g2-8-50\n",
      "[97/100] g2-8-60\n",
      "[98/100] g2-8-70\n",
      "[99/100] g2-8-80\n",
      "[100/100] g2-8-90\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "n_iter = 60\n",
    "\n",
    "VERSION = '0.1.3'\n",
    "\n",
    "# Specify the directory path you want to list files from\n",
    "directory_path = '../data/raw/g2-txt'\n",
    "\n",
    "# Get a list of all files in the directory (excluding directories)\n",
    "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "total_files = len(files)\n",
    "\n",
    "# List all files in the specified directory\n",
    "for index, filename in enumerate(files, start=1):\n",
    "    if os.path.isfile(os.path.join(directory_path, filename)):\n",
    "        print(f\"[{index}/{total_files}] {filename.split('.')[0]}\")\n",
    "# \n",
    "#         \n",
    "#         FILE_NAME = filename.split('.')[0]\n",
    "#         file_path = rf'..\\data\\raw\\g2-txt\\{FILE_NAME}.txt'\n",
    "#         \n",
    "#         # The regular expression '\\s+' can be used to match one or more spaces\n",
    "#         data = pd.read_csv(file_path, sep=\"\\s+\", header=None, names=['X', 'Y'])\n",
    "#         # Check the first few rows of your DataFrame\n",
    "#         data.head()\n",
    "#         # Check for NaN or missing values\n",
    "#         data.isna().sum()\n",
    "#         data.shape\n",
    "#         # Remove rows with missing values:\n",
    "#         data_clean = data.dropna()\n",
    "#         \n",
    "#         # Replace missing values (e.g., with the mean):\n",
    "#         # data_clean = data.fillna(data.mean())\n",
    "#         data.shape\n",
    "#         plt.scatter(data_clean['X'], data_clean['Y'])\n",
    "#         plt.title('Initial Data Visualization')\n",
    "#         plt.xlabel('X')\n",
    "#         plt.ylabel('Y')\n",
    "#         plt.show()\n",
    "#         processed_data = preprocess_data(data)\n",
    "#         processed_data.head()\n",
    "#         plt.scatter(processed_data['X'], processed_data['Y'])\n",
    "#         plt.title('Processed Data Visualization')\n",
    "#         plt.xlabel('X')\n",
    "#         plt.ylabel('Y')\n",
    "#         plt.show()\n",
    "#         # Save the processed data to a CSV file\n",
    "#         processed_data_path = rf'..\\data\\processed\\g2\\{FILE_NAME}.txt'\n",
    "#         processed_data.to_csv(processed_data_path, index=False)\n",
    "#         processed_data_path\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T21:18:48.105495300Z",
     "start_time": "2024-02-16T21:18:48.081087400Z"
    }
   },
   "id": "6dffb45fc9672712",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] g2-1024-10\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[2/100] g2-1024-100\n",
      "{'algorithm': 'full', 'copy_x': True, 'init': 'k-means++', 'max_iter': 5000, 'n_clusters': 2, 'n_init': 15, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.744140625 \n",
      "\n",
      "[3/100] g2-1024-20\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[4/100] g2-1024-30\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.998046875 \n",
      "\n",
      "[5/100] g2-1024-40\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.96484375 \n",
      "\n",
      "[6/100] g2-1024-50\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.921875 \n",
      "\n",
      "[7/100] g2-1024-60\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 60000, 'n_clusters': 2, 'n_init': 15, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.896484375 \n",
      "\n",
      "[8/100] g2-1024-70\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.865234375 \n",
      "\n",
      "[9/100] g2-1024-80\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.8203125 \n",
      "\n",
      "[10/100] g2-1024-90\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.74609375 \n",
      "\n",
      "[11/100] g2-128-10\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[12/100] g2-128-100\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'k-means++', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.720703125 \n",
      "\n",
      "[13/100] g2-128-20\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[14/100] g2-128-30\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.994140625 \n",
      "\n",
      "[15/100] g2-128-40\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.962890625 \n",
      "\n",
      "[16/100] g2-128-50\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.91796875 \n",
      "\n",
      "[17/100] g2-128-60\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.88671875 \n",
      "\n",
      "[18/100] g2-128-70\n",
      "{'algorithm': 'full', 'copy_x': True, 'init': 'k-means++', 'max_iter': 300, 'n_clusters': 2, 'n_init': 95, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.849609375 \n",
      "[19/100] g2-128-80\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.8125 \n",
      "\n",
      "[20/100] g2-128-90\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.76171875 \n",
      "\n",
      "[21/100] g2-16-10\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[22/100] g2-16-100\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.7578125 \n",
      "\n",
      "[23/100] g2-16-20\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[24/100] g2-16-30\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.98828125 \n",
      "\n",
      "[25/100] g2-16-40\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.953125 \n",
      "\n",
      "[26/100] g2-16-50\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.931640625 \n",
      "\n",
      "[27/100] g2-16-60\n",
      "{'algorithm': 'full', 'copy_x': True, 'init': 'k-means++', 'max_iter': 300, 'n_clusters': 2, 'n_init': 95, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.875 \n",
      "[28/100] g2-16-70\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.826171875 \n",
      "\n",
      "[29/100] g2-16-80\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.837890625 \n",
      "\n",
      "[30/100] g2-16-90\n",
      "{'algorithm': 'full', 'copy_x': True, 'init': 'k-means++', 'max_iter': 300, 'n_clusters': 2, 'n_init': 95, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.767578125 \n",
      "[31/100] g2-2-10\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[32/100] g2-2-100\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'k-means++', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.763671875 \n",
      "\n",
      "[33/100] g2-2-20\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[34/100] g2-2-30\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.99609375 \n",
      "\n",
      "[35/100] g2-2-40\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.974609375 \n",
      "\n",
      "[36/100] g2-2-50\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.91796875 \n",
      "\n",
      "[37/100] g2-2-60\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.888671875 \n",
      "\n",
      "[38/100] g2-2-70\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.841796875 \n",
      "\n",
      "[39/100] g2-2-80\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.798828125 \n",
      "\n",
      "[40/100] g2-2-90\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.744140625 \n",
      "\n",
      "[41/100] g2-256-10\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[42/100] g2-256-100\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'k-means++', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.783203125 \n",
      "\n",
      "[43/100] g2-256-20\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.998046875 \n",
      "\n",
      "[44/100] g2-256-30\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.998046875 \n",
      "\n",
      "[45/100] g2-256-40\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.9609375 \n",
      "\n",
      "[46/100] g2-256-50\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.923828125 \n",
      "\n",
      "[47/100] g2-256-60\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.87890625 \n",
      "\n",
      "[48/100] g2-256-70\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.853515625 \n",
      "\n",
      "[49/100] g2-256-80\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.79296875 \n",
      "\n",
      "[50/100] g2-256-90\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.759765625 \n",
      "\n",
      "[51/100] g2-32-10\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[52/100] g2-32-100\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.7734375 \n",
      "\n",
      "[53/100] g2-32-20\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[54/100] g2-32-30\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.986328125 \n",
      "\n",
      "[55/100] g2-32-40\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.9609375 \n",
      "\n",
      "[56/100] g2-32-50\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.900390625 \n",
      "\n",
      "[57/100] g2-32-60\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.865234375 \n",
      "\n",
      "[58/100] g2-32-70\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.8515625 \n",
      "\n",
      "[59/100] g2-32-80\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.82421875 \n",
      "\n",
      "[60/100] g2-32-90\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.80078125 \n",
      "\n",
      "[61/100] g2-4-10\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[62/100] g2-4-100\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.759765625 \n",
      "\n",
      "[63/100] g2-4-20\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[64/100] g2-4-30\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.9921875 \n",
      "\n",
      "[65/100] g2-4-40\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.95703125 \n",
      "\n",
      "[66/100] g2-4-50\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.92578125 \n",
      "\n",
      "[67/100] g2-4-60\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.888671875 \n",
      "\n",
      "[68/100] g2-4-70\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.833984375 \n",
      "\n",
      "[69/100] g2-4-80\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.818359375 \n",
      "\n",
      "[70/100] g2-4-90\n",
      "{'algorithm': 'full', 'copy_x': True, 'init': 'k-means++', 'max_iter': 300, 'n_clusters': 2, 'n_init': 95, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.775390625 \n",
      "[71/100] g2-512-10\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[72/100] g2-512-100\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.771484375 \n",
      "\n",
      "[73/100] g2-512-20\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[74/100] g2-512-30\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.9921875 \n",
      "\n",
      "[75/100] g2-512-40\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.96484375 \n",
      "\n",
      "[76/100] g2-512-50\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.927734375 \n",
      "\n",
      "[77/100] g2-512-60\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.89453125 \n",
      "\n",
      "[78/100] g2-512-70\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.83984375 \n",
      "\n",
      "[79/100] g2-512-80\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.81640625 \n",
      "\n",
      "[80/100] g2-512-90\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.77734375 \n",
      "\n",
      "[81/100] g2-64-10\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[82/100] g2-64-100\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'k-means++', 'max_iter': 40000, 'n_clusters': 2, 'n_init': 75, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.724609375 \n",
      "[83/100] g2-64-20\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[84/100] g2-64-30\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.9921875 \n",
      "\n",
      "[85/100] g2-64-40\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.955078125 \n",
      "\n",
      "[86/100] g2-64-50\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.921875 \n",
      "\n",
      "[87/100] g2-64-60\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.8984375 \n",
      "\n",
      "[88/100] g2-64-70\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.8359375 \n",
      "\n",
      "[89/100] g2-64-80\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.7890625 \n",
      "\n",
      "[90/100] g2-64-90\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.82421875 \n",
      "\n",
      "[91/100] g2-8-10\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[92/100] g2-8-100\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'k-means++', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.7734375 \n",
      "\n",
      "[93/100] g2-8-20\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "1.0 \n",
      "\n",
      "[94/100] g2-8-30\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.9921875 \n",
      "\n",
      "[95/100] g2-8-40\n",
      "{'algorithm': 'full', 'copy_x': True, 'init': 'k-means++', 'max_iter': 300, 'n_clusters': 2, 'n_init': 95, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.966796875 \n",
      "[96/100] g2-8-50\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.91015625 \n",
      "\n",
      "[97/100] g2-8-60\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.833984375 \n",
      "\n",
      "[98/100] g2-8-70\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.849609375 \n",
      "\n",
      "[99/100] g2-8-80\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.826171875 \n",
      "\n",
      "[100/100] g2-8-90\n",
      "{'algorithm': 'auto', 'copy_x': True, 'init': 'random', 'max_iter': 300, 'n_clusters': 2, 'n_init': 5, 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "0.771484375 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from src.utils_clustering_v2 import load_labels_from_file, map_clusters_to_ground_truth, evaluate_clustering, \\\n",
    "    generate_confusion_matrix\n",
    "\n",
    "# Specify the directory path you want to list files from\n",
    "directory_path = '../data/raw/g2-txt'\n",
    "\n",
    "# Get a list of all files in the directory (excluding directories)\n",
    "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "total_files = len(files)\n",
    "\n",
    "# List all files in the specified directory\n",
    "for index, filename in enumerate(files, start=1):\n",
    "    if os.path.isfile(os.path.join(directory_path, filename)):\n",
    "        print(f\"[{index}/{total_files}] {filename.split('.')[0]}\")\n",
    "        DATASET_FILE_NAME = filename.split('.')[0]\n",
    "        LABELS_FILE_NAME = f'{DATASET_FILE_NAME}-gt.pa'\n",
    "        labels_true = load_labels_from_file(rf'..\\data\\label\\g2-gt-pa\\{LABELS_FILE_NAME}', 15)\n",
    "        N_CLUSTERS = len(set(labels_true))\n",
    "        \n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        file_path = rf'..\\data\\processed\\g2\\{DATASET_FILE_NAME}.txt'\n",
    "        processed_data = pd.read_csv(file_path)\n",
    "        LABELS_FILE_NAME = f'{DATASET_FILE_NAME}.pa'\n",
    "        \n",
    "        clustering_algorithm_name = 'KMeans_clustering'\n",
    "        dataset_name = DATASET_FILE_NAME\n",
    "        # Evaluating Clustering Algorithm with Train, Validation, and Test Sets\n",
    "        \n",
    "        # Split the data into train and temp (temp will contain both validate and test)\n",
    "        train_data, temp_data, train_labels, temp_labels = train_test_split(\n",
    "            processed_data, labels_true, train_size=0.5, random_state=42)\n",
    "        \n",
    "        # Split the temp data into validate and test\n",
    "        validate_data, test_data, validate_labels, test_labels = train_test_split(\n",
    "            temp_data, temp_labels, train_size=0.5, random_state=42)\n",
    "        \n",
    "        # You now have train_data, validate_data, and test_data\n",
    "        # print(f\"Train set size: {len(train_data)}\")\n",
    "        # print(f\"Validate set size: {len(validate_data)}\")\n",
    "        # print(f\"Test set size: {len(test_data)}\")\n",
    "        \n",
    "        hyperparameter_domains = {\n",
    "            'n_clusters': [N_CLUSTERS],\n",
    "            'init': ['k-means++', 'random'],\n",
    "            'n_init': np.arange(5, 100, 10),\n",
    "            'max_iter': [100, 300, 1000, 2000, 5000, 10000, 20000, 40000, 60000, 80000],\n",
    "            'algorithm': ['auto', 'elkan', 'full']\n",
    "        }\n",
    "        \n",
    "        from sklearn.cluster import KMeans\n",
    "        import time\n",
    "        from sklearn.model_selection import ParameterSampler\n",
    "        \n",
    "        \n",
    "        def calculate_grid_size(space):\n",
    "            # For each parameter, count the number of unique values and multiply them\n",
    "            return np.prod([len(values) for values in space.values()])\n",
    "        \n",
    "        \n",
    "        grid_size = calculate_grid_size(hyperparameter_domains)\n",
    "        # print(f\"{clustering_algorithm_name} hyperparameter grid size: {grid_size}\")\n",
    "        results_path = rf'../results/metrics/results_kmeans_{DATASET_FILE_NAME}_v{VERSION}.csv'\n",
    "        \n",
    "        # Sample configurations\n",
    "        \n",
    "        parameter_sampler = ParameterSampler(hyperparameter_domains, n_iter=n_iter, random_state=42)\n",
    "        \n",
    "        # Debugging: Print the number of configurations to run\n",
    "        # print(f\"Total configurations to run: {n_iter}\")\n",
    "        \n",
    "        # Run clustering for each configuration\n",
    "        for i, params in enumerate(parameter_sampler, start=1):\n",
    "            # print(f\"Running configuration {i}/{n_iter}: {params}\")  # Debugging: print before running\n",
    "            start_time = time.time()\n",
    "        \n",
    "            # Initialize and fit KMeans\n",
    "            kmeans_clustering = KMeans(**params, random_state=42)\n",
    "        \n",
    "            # Start timing the training phase\n",
    "            training_start_time = time.time()\n",
    "        \n",
    "            # Fit KMeans using only the training data\n",
    "            kmeans_clustering.fit(train_data)\n",
    "        \n",
    "            # End timing the training phase\n",
    "            training_end_time = time.time()\n",
    "            training_time = (training_end_time - training_start_time)\n",
    "        \n",
    "            # Start timing the prediction phase\n",
    "            prediction_start_time = time.time()\n",
    "        \n",
    "            # Predict labels for the validation or test data\n",
    "            labels_pred = kmeans_clustering.predict(validate_data)\n",
    "        \n",
    "            # End timing the prediction phase\n",
    "            prediction_end_time = time.time()\n",
    "            prediction_time = (prediction_end_time - prediction_start_time)\n",
    "        \n",
    "            algorithm_params = kmeans_clustering.get_params()\n",
    "            algorithm_details = str(algorithm_params)\n",
    "        \n",
    "            labels_pred = map_clusters_to_ground_truth(validate_labels, labels_pred)\n",
    "            evaluate_clustering(X=validate_data, labels_true=validate_labels, labels_pred=labels_pred,\n",
    "                                clus_algo_name=clustering_algorithm_name, dataset_name=dataset_name,\n",
    "                                results_path=results_path, algorithm_details=algorithm_details,\n",
    "                                training_time=training_time, prediction_time=prediction_time)\n",
    "            # generate_confusion_matrix(labels_true, labels_pred, N_CLUSTERS)\n",
    "        FILE_NAME = f'results_kmeans_{DATASET_FILE_NAME}_v{VERSION}.csv'\n",
    "        file_path = rf'..\\results\\metrics\\{FILE_NAME}'\n",
    "        csv_content = pd.read_csv(file_path)\n",
    "        \n",
    "        # Find the record with the highest accuracy\n",
    "        max_accuracy_record = csv_content.loc[csv_content['Accuracy'].idxmax()]\n",
    "        \n",
    "        # Display the record with the highest accuracy\n",
    "        # print(max_accuracy_record)\n",
    "        print(max_accuracy_record['Algorithm Details'])\n",
    "        print(max_accuracy_record['Accuracy'],\"\\n\")\n",
    "        results_path = rf'../results/metrics/results_kmeans_final_{DATASET_FILE_NAME}_v{VERSION}.csv'\n",
    "        \n",
    "        combined_train_data = pd.concat([train_data, validate_data])\n",
    "        combined_train_labels = np.concatenate([train_labels, validate_labels])\n",
    "        \n",
    "        # Initialize KMeans with the best hyperparameters\n",
    "        best_params = max_accuracy_record['Algorithm Details']  # Assume this contains the best parameters\n",
    "        kmeans_final = KMeans(**eval(best_params))\n",
    "        \n",
    "        # Start timing the training phase\n",
    "        training_start_time = time.time()\n",
    "        \n",
    "        # Retrain using the combined dataset\n",
    "        kmeans_final.fit(combined_train_data)\n",
    "        \n",
    "        # End timing the training phase\n",
    "        training_end_time = time.time()\n",
    "        training_time = (training_end_time - training_start_time)\n",
    "        \n",
    "        # Start timing the prediction phase\n",
    "        prediction_start_time = time.time()\n",
    "        \n",
    "        # Predict on the test set\n",
    "        final_labels_pred = kmeans_final.predict(test_data)\n",
    "        \n",
    "        # End timing the prediction phase\n",
    "        prediction_end_time = time.time()\n",
    "        prediction_time = (prediction_end_time - prediction_start_time)\n",
    "        \n",
    "        algorithm_params = kmeans_final.get_params()\n",
    "        algorithm_details = str(algorithm_params)\n",
    "        \n",
    "        # Map predicted labels to ground truth labels for the test set\n",
    "        final_labels_pred = map_clusters_to_ground_truth(test_labels, final_labels_pred)\n",
    "        # generate_confusion_matrix(test_labels, final_labels_pred, N_CLUSTERS)\n",
    "        \n",
    "        evaluate_clustering(X=test_data, labels_true=test_labels, labels_pred=final_labels_pred,\n",
    "                            clus_algo_name=clustering_algorithm_name, dataset_name=dataset_name,\n",
    "                            results_path=results_path, algorithm_details=algorithm_details,\n",
    "                            training_time=training_time, prediction_time=prediction_time)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T21:45:00.242308100Z",
     "start_time": "2024-02-16T21:18:48.103993Z"
    }
   },
   "id": "6941ddb5d2974c68",
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
